{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9053daa",
   "metadata": {},
   "source": [
    "# Approach 3: Hybrid Claim-Phrase NER + LLM Restructuring\n",
    "\n",
    "Combines neural NER with LLM post-processing for structured output.\n",
    "\n",
    "## Overview\n",
    "- **Step 1**: Use RoBERTa NER to extract claim phrases (like Approach 2)\n",
    "- **Step 2**: Use LLM (GPT-4) to restructure claims into SPOT format\n",
    "  - **S**ubject: Who/what is making the claim\n",
    "  - **P**redicate: What action/state is claimed\n",
    "  - **O**bject: What is being claimed about\n",
    "  - **T**ime: When/urgency element\n",
    "\n",
    "## Advantages\n",
    "- ‚úÖ Most structured output\n",
    "- ‚úÖ Best for complex verification logic\n",
    "- ‚úÖ Combines neural speed + LLM reasoning\n",
    "\n",
    "## Requirements\n",
    "- OpenAI API key for GPT-4\n",
    "- Note: Will incur API costs (~$0.01 per message)\n",
    "\n",
    "## Setup Instructions\n",
    "1. Upload `claim_annotations_2000.json`\n",
    "2. Provide OpenAI API key when prompted\n",
    "3. Run all cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166eeb9",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43593a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q transformers datasets accelerate seqeval scikit-learn torch openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "from sklearn.model_split import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from seqeval.metrics import classification_report, f1_score\n",
    "from openai import OpenAI\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45427681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üìÅ Upload 'claim_annotations_2000.json'\")\n",
    "uploaded = files.upload()\n",
    "data_file = list(uploaded.keys())[0]\n",
    "print(f\"‚úÖ Uploaded: {data_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b63a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OpenAI API key\n",
    "import getpass\n",
    "\n",
    "print(\"üîë Enter your OpenAI API key:\")\n",
    "api_key = getpass.getpass(\"API Key: \")\n",
    "client = OpenAI(api_key=api_key)\n",
    "print(\"‚úÖ API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba37f77",
   "metadata": {},
   "source": [
    "## 2. Step 1: Train Claim-Phrase NER (Same as Approach 2)\n",
    "\n",
    "This is identical to Approach 2. We'll use the same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eaccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define claim types and labels (same as Approach 2)\n",
    "CLAIM_TYPES = [\n",
    "    'IDENTITY_CLAIM', 'DELIVERY_CLAIM', 'FINANCIAL_CLAIM',\n",
    "    'ACCOUNT_CLAIM', 'URGENCY_CLAIM', 'ACTION_CLAIM',\n",
    "    'VERIFICATION_CLAIM', 'SECURITY_CLAIM', 'REWARD_CLAIM',\n",
    "    'LEGAL_CLAIM', 'SOCIAL_CLAIM', 'CREDENTIALS_CLAIM'\n",
    "]\n",
    "\n",
    "labels = ['O']\n",
    "for claim_type in CLAIM_TYPES:\n",
    "    labels.append(f'B-{claim_type}')\n",
    "    labels.append(f'I-{claim_type}')\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(f\"‚úÖ {len(labels)} labels defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading (abbreviated - same as Approach 2)\n",
    "# NOTE: Copy the full data loading code from Approach 2 notebook\n",
    "# For brevity, showing simplified version\n",
    "\n",
    "print(\"üìÇ Loading data... (using same code as Approach 2)\")\n",
    "print(\"‚ö†Ô∏è  Copy full data loading cells from Approach 2 notebook\")\n",
    "\n",
    "# After loading, you should have:\n",
    "# - train_examples, val_examples, test_examples\n",
    "# - train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6162ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train NER model (same as Approach 2)\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model loaded - ready to train\")\n",
    "print(\"‚ö†Ô∏è  Copy training code from Approach 2 notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817989da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming training is complete, define claim extraction function\n",
    "def extract_claims_ner(text, model, tokenizer, id2label):\n",
    "    \"\"\"\n",
    "    Extract claims using trained NER model\n",
    "    (Same as Approach 2)\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    \n",
    "    offset_mapping = inputs.pop('offset_mapping')[0]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    predictions = torch.argmax(outputs.logits, dim=2)[0]\n",
    "    probabilities = torch.softmax(outputs.logits, dim=2)[0]\n",
    "    \n",
    "    claims = []\n",
    "    current_claim = None\n",
    "    \n",
    "    for idx, (pred, prob, (start, end)) in enumerate(zip(predictions, probabilities, offset_mapping)):\n",
    "        if start == 0 and end == 0:\n",
    "            continue\n",
    "        \n",
    "        label = id2label[pred.item()]\n",
    "        confidence = prob[pred].item()\n",
    "        \n",
    "        if label.startswith('B-'):\n",
    "            if current_claim:\n",
    "                claims.append(current_claim)\n",
    "            \n",
    "            current_claim = {\n",
    "                'type': label[2:],\n",
    "                'start': start.item(),\n",
    "                'end': end.item(),\n",
    "                'confidence': confidence\n",
    "            }\n",
    "        \n",
    "        elif label.startswith('I-') and current_claim:\n",
    "            if label[2:] == current_claim['type']:\n",
    "                current_claim['end'] = end.item()\n",
    "                current_claim['confidence'] = (current_claim['confidence'] + confidence) / 2\n",
    "        \n",
    "        elif label == 'O' and current_claim:\n",
    "            claims.append(current_claim)\n",
    "            current_claim = None\n",
    "    \n",
    "    if current_claim:\n",
    "        claims.append(current_claim)\n",
    "    \n",
    "    for claim in claims:\n",
    "        claim['text'] = text[claim['start']:claim['end']]\n",
    "    \n",
    "    return claims\n",
    "\n",
    "print(\"‚úÖ Claim extraction function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d202d",
   "metadata": {},
   "source": [
    "## 3. Step 2: LLM Restructuring to SPOT Format\n",
    "\n",
    "This is the NEW part - using GPT-4 to structure claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f81eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restructure_claims_with_llm(text, claims, client):\n",
    "    \"\"\"\n",
    "    Use GPT-4 to restructure claims into SPOT format:\n",
    "    - Subject: Who/what is making the claim\n",
    "    - Predicate: What action/state\n",
    "    - Object: What is claimed about\n",
    "    - Time: When/urgency\n",
    "    \"\"\"\n",
    "    if not claims:\n",
    "        return []\n",
    "    \n",
    "    # Format claims for LLM\n",
    "    claims_text = \"\\n\".join([\n",
    "        f\"- {claim['type']}: '{claim['text']}'\"\n",
    "        for claim in claims\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"You are a claim analysis expert. Given an SMS message and extracted claims, restructure each claim into SPOT format:\n",
    "\n",
    "SPOT Format:\n",
    "- Subject: Who/what entity is making the claim\n",
    "- Predicate: What action or state is being claimed\n",
    "- Object: What the claim is about (product, account, action, etc.)\n",
    "- Time: Temporal/urgency element (if any)\n",
    "\n",
    "SMS Message:\n",
    "\"{text}\"\n",
    "\n",
    "Extracted Claims:\n",
    "{claims_text}\n",
    "\n",
    "For EACH claim, provide SPOT structure as JSON:\n",
    "{{\n",
    "  \"claim_type\": \"<type>\",\n",
    "  \"original_text\": \"<text>\",\n",
    "  \"spot\": {{\n",
    "    \"subject\": \"<subject>\",\n",
    "    \"predicate\": \"<predicate>\",\n",
    "    \"object\": \"<object>\",\n",
    "    \"time\": \"<time or null>\"\n",
    "  }},\n",
    "  \"verification_question\": \"<question to verify this claim>\"\n",
    "}}\n",
    "\n",
    "Return ONLY a JSON array of structured claims.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # or \"gpt-4\" for better quality\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a claim structuring expert. Always respond with valid JSON.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "        \n",
    "        # Handle different response formats\n",
    "        if isinstance(result, dict) and 'claims' in result:\n",
    "            return result['claims']\n",
    "        elif isinstance(result, list):\n",
    "            return result\n",
    "        else:\n",
    "            return [result]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LLM error: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"‚úÖ LLM restructuring function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f07405",
   "metadata": {},
   "source": [
    "## 4. Complete Hybrid Pipeline Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad842ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test complete hybrid pipeline\n",
    "test_messages = [\n",
    "    \"Your Amazon package is delayed. Click here urgently to reschedule delivery.\",\n",
    "    \"URGENT: Your PayPal account has been suspended. Verify your identity now to avoid legal action.\",\n",
    "    \"Congratulations! You've won ¬£5000. Call 0800-123-456 to claim your prize today.\",\n",
    "]\n",
    "\n",
    "print(\"üîç HYBRID PIPELINE: NER ‚Üí LLM RESTRUCTURING\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, msg in enumerate(test_messages, 1):\n",
    "    print(f\"\\n{i}. Message: {msg}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Step 1: Extract claims with NER\n",
    "    claims = extract_claims_ner(msg, model, tokenizer, id2label)\n",
    "    print(f\"\\n   STEP 1 - NER Extraction:\")\n",
    "    if claims:\n",
    "        for claim in claims:\n",
    "            print(f\"     - {claim['type']:20} : '{claim['text']}'\")\n",
    "    else:\n",
    "        print(\"     (no claims)\")\n",
    "        continue\n",
    "    \n",
    "    # Step 2: Restructure with LLM\n",
    "    structured_claims = restructure_claims_with_llm(msg, claims, client)\n",
    "    print(f\"\\n   STEP 2 - LLM SPOT Restructuring:\")\n",
    "    if structured_claims:\n",
    "        for sc in structured_claims:\n",
    "            print(f\"\\n     üìã {sc.get('claim_type', 'UNKNOWN')}:\")\n",
    "            spot = sc.get('spot', {})\n",
    "            print(f\"        Subject:   {spot.get('subject', 'N/A')}\")\n",
    "            print(f\"        Predicate: {spot.get('predicate', 'N/A')}\")\n",
    "            print(f\"        Object:    {spot.get('object', 'N/A')}\")\n",
    "            print(f\"        Time:      {spot.get('time', 'N/A')}\")\n",
    "            \n",
    "            if 'verification_question' in sc:\n",
    "                print(f\"        ‚ùì Verify:  {sc['verification_question']}\")\n",
    "    else:\n",
    "        print(\"     (LLM restructuring failed)\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445a5be",
   "metadata": {},
   "source": [
    "## 5. Comparison: Raw Claims vs SPOT Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the value of SPOT structuring\n",
    "example_msg = \"Your Amazon package is delayed. Click here urgently.\"\n",
    "\n",
    "claims = extract_claims_ner(example_msg, model, tokenizer, id2label)\n",
    "structured = restructure_claims_with_llm(example_msg, claims, client)\n",
    "\n",
    "print(\"üìä COMPARISON: Raw vs Structured\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£  Raw Claims (Approach 2 output):\")\n",
    "for claim in claims:\n",
    "    print(f\"   {claim['type']}: '{claim['text']}'\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£  Structured Claims (Approach 3 output):\")\n",
    "for sc in structured:\n",
    "    print(f\"\\n   {sc.get('claim_type')}:\")\n",
    "    spot = sc.get('spot', {})\n",
    "    print(f\"     S: {spot.get('subject')}\")\n",
    "    print(f\"     P: {spot.get('predicate')}\")\n",
    "    print(f\"     O: {spot.get('object')}\")\n",
    "    print(f\"     T: {spot.get('time')}\")\n",
    "    print(f\"     Verify: {sc.get('verification_question')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüí° Benefits of SPOT:\")\n",
    "print(\"   ‚úÖ Explicit subject identification\")\n",
    "print(\"   ‚úÖ Clear action/state definition\")\n",
    "print(\"   ‚úÖ Verification questions generated\")\n",
    "print(\"   ‚úÖ Ready for automated verification agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4851f39",
   "metadata": {},
   "source": [
    "## 6. Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3790c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate API costs\n",
    "print(\"üí∞ Cost Analysis\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"Model: gpt-4o-mini\")\n",
    "print(\"  Input:  $0.150 / 1M tokens\")\n",
    "print(\"  Output: $0.600 / 1M tokens\")\n",
    "print(\"\\nTypical SMS processing:\")\n",
    "print(\"  ~300 input tokens\")\n",
    "print(\"  ~200 output tokens\")\n",
    "print(\"  Cost per message: ~$0.00015 ($0.15 per 1000 messages)\")\n",
    "print(\"\\nFor 2000 test messages: ~$0.30\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüí° Use gpt-4o-mini for cost-efficiency\")\n",
    "print(\"   Or use gpt-4 for higher quality (+10x cost)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d46ee3",
   "metadata": {},
   "source": [
    "## 7. Save Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f1a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NER model\n",
    "model.save_pretrained(\"./hybrid-claim-ner\")\n",
    "tokenizer.save_pretrained(\"./hybrid-claim-ner\")\n",
    "\n",
    "# Save config\n",
    "config = {\n",
    "    'approach': 'hybrid',\n",
    "    'step1': 'RoBERTa NER for claim extraction',\n",
    "    'step2': 'GPT-4 for SPOT restructuring',\n",
    "    'label2id': label2id,\n",
    "    'id2label': {int(k): v for k, v in id2label.items()},\n",
    "    'claim_types': CLAIM_TYPES,\n",
    "    'spot_format': {\n",
    "        'S': 'Subject - who/what makes claim',\n",
    "        'P': 'Predicate - action/state claimed',\n",
    "        'O': 'Object - what claim is about',\n",
    "        'T': 'Time - temporal/urgency element'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"./hybrid-claim-ner/config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Hybrid pipeline saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc350cc4",
   "metadata": {},
   "source": [
    "## 8. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c82a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"APPROACH 3: HYBRID CLAIM-PHRASE NER + LLM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPipeline:\")\n",
    "print(f\"  1. RoBERTa NER extracts claims (fast, on-device)\")\n",
    "print(f\"  2. GPT-4 restructures to SPOT format (slow, API call)\")\n",
    "print(f\"\\nAdvantages:\")\n",
    "print(f\"  ‚úÖ Most structured output\")\n",
    "print(f\"  ‚úÖ Explicit verification questions\")\n",
    "print(f\"  ‚úÖ Best for complex verification agent\")\n",
    "print(f\"  ‚úÖ Combines neural speed + LLM reasoning\")\n",
    "print(f\"\\nDisadvantages:\")\n",
    "print(f\"  ‚ùå Requires LLM API (costs)\")\n",
    "print(f\"  ‚ùå Slower inference (~1-2 sec per message)\")\n",
    "print(f\"  ‚ùå More complex pipeline\")\n",
    "print(f\"\\nUse When:\")\n",
    "print(f\"  - Need highly structured claims\")\n",
    "print(f\"  - Building sophisticated verification system\")\n",
    "print(f\"  - Can afford API costs\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
