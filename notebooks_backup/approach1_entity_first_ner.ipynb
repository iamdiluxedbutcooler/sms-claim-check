{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd311893",
   "metadata": {},
   "source": [
    "# Approach 1: Entity-First NER\n",
    "\n",
    "Two-step approach: Extract entities first, then parse them into claims.\n",
    "\n",
    "## Overview\n",
    "- **Step 1**: Train RoBERTa-based NER to extract entities (BRAND, PHONE, URL, EMAIL, etc.)\n",
    "- **Step 2**: Parse extracted entities into structured claims using rules\n",
    "- **Advantages**: Entities are concrete, clear intermediate representation, reusable\n",
    "- **Use Case**: When you need explicit entity extraction for other purposes\n",
    "\n",
    "## Entity Types\n",
    "- BRAND (Amazon, PayPal, IRS, etc.)\n",
    "- PHONE (phone numbers)\n",
    "- URL (links)\n",
    "- EMAIL (email addresses)\n",
    "- AMOUNT (monetary amounts)\n",
    "- DATE (time references)\n",
    "- ACCOUNT (account numbers/references)\n",
    "\n",
    "## Setup Instructions\n",
    "1. Upload `entity_annotations_2000.json` to Colab\n",
    "2. Run all cells in order\n",
    "3. Model extracts entities, then parses to claims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6eff47",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets accelerate seqeval scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf4e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data file\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üìÅ Please upload 'entity_annotations_2000.json'\")\n",
    "uploaded = files.upload()\n",
    "data_file = list(uploaded.keys())[0]\n",
    "print(f\"‚úÖ Uploaded: {data_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba20b90c",
   "metadata": {},
   "source": [
    "## 2. Define Entity Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb60bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define entity types\n",
    "ENTITY_TYPES = [\n",
    "    'BRAND',      # Company/organization names\n",
    "    'PHONE',      # Phone numbers\n",
    "    'URL',        # Web links\n",
    "    'EMAIL',      # Email addresses\n",
    "    'AMOUNT',     # Money/prizes\n",
    "    'DATE',       # Time references\n",
    "    'ACCOUNT',    # Account numbers/IDs\n",
    "    'PERSON',     # Person names\n",
    "    'LOCATION'    # Places\n",
    "]\n",
    "\n",
    "# Create BIO labels\n",
    "labels = ['O']  # Outside\n",
    "for entity_type in ENTITY_TYPES:\n",
    "    labels.append(f'B-{entity_type}')\n",
    "    labels.append(f'I-{entity_type}')\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(f\"Total labels: {len(labels)}\")\n",
    "print(f\"Entity types: {len(ENTITY_TYPES)}\")\n",
    "print(f\"Labels: {labels[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04958456",
   "metadata": {},
   "source": [
    "## 3. Data Loading (Same as Approach 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db92d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bio_format(text, entity_spans):\n",
    "    \"\"\"\n",
    "    Convert text and entity spans to BIO format\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    bio_labels = ['O'] * len(words)\n",
    "    \n",
    "    char_pos = 0\n",
    "    \n",
    "    for word_idx, word in enumerate(words):\n",
    "        word_start = text.find(word, char_pos)\n",
    "        if word_start == -1:\n",
    "            continue\n",
    "            \n",
    "        word_end = word_start + len(word)\n",
    "        char_pos = word_end\n",
    "        \n",
    "        for span in entity_spans:\n",
    "            span_start = span['start']\n",
    "            span_end = span['end']\n",
    "            entity_label = span['label']\n",
    "            \n",
    "            if not (word_end <= span_start or word_start >= span_end):\n",
    "                if word_start <= span_start < word_end:\n",
    "                    bio_labels[word_idx] = f'B-{entity_label}'\n",
    "                else:\n",
    "                    if word_idx > 0 and bio_labels[word_idx-1] in [f'B-{entity_label}', f'I-{entity_label}']:\n",
    "                        bio_labels[word_idx] = f'I-{entity_label}'\n",
    "                    else:\n",
    "                        bio_labels[word_idx] = f'B-{entity_label}'\n",
    "                break\n",
    "    \n",
    "    return words, bio_labels\n",
    "\n",
    "def load_entity_data(json_file):\n",
    "    \"\"\"Load entity annotations\"\"\"\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    examples = []\n",
    "    \n",
    "    for entry in data:\n",
    "        text = entry['data']['text']\n",
    "        \n",
    "        if not entry.get('annotations') or len(entry['annotations']) == 0:\n",
    "            continue\n",
    "        \n",
    "        annotations = entry['annotations'][0]\n",
    "        \n",
    "        entity_spans = []\n",
    "        if 'result' in annotations and annotations['result']:\n",
    "            for result in annotations['result']:\n",
    "                value = result.get('value', {})\n",
    "                labels_list = value.get('labels', [])\n",
    "                \n",
    "                if labels_list:\n",
    "                    entity_spans.append({\n",
    "                        'text': value.get('text', ''),\n",
    "                        'start': value.get('start', 0),\n",
    "                        'end': value.get('end', 0),\n",
    "                        'label': labels_list[0]\n",
    "                    })\n",
    "        \n",
    "        tokens, bio_labels = convert_to_bio_format(text, entity_spans)\n",
    "        \n",
    "        examples.append({\n",
    "            'id': entry.get('id'),\n",
    "            'text': text,\n",
    "            'tokens': tokens,\n",
    "            'labels': bio_labels,\n",
    "            'entity_spans': entity_spans\n",
    "        })\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "examples = load_entity_data(data_file)\n",
    "print(f\"‚úÖ Loaded {len(examples)} examples\")\n",
    "\n",
    "# Show example\n",
    "print(\"\\nüìù First example with entities:\")\n",
    "for ex in examples[:5]:\n",
    "    if ex['entity_spans']:\n",
    "        print(f\"  Text: {ex['text'][:60]}...\")\n",
    "        print(f\"  Entities: {len(ex['entity_spans'])}\")\n",
    "        for span in ex['entity_spans'][:3]:\n",
    "            print(f\"    - {span['label']:10} : '{span['text']}'\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716baa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_examples, test_examples = train_test_split(examples, test_size=0.15, random_state=42)\n",
    "train_examples, val_examples = train_test_split(train_examples, test_size=0.176, random_state=42)\n",
    "\n",
    "print(f\"Dataset split:\")\n",
    "print(f\"  Train: {len(train_examples)} examples\")\n",
    "print(f\"  Val:   {len(val_examples)} examples\")\n",
    "print(f\"  Test:  {len(test_examples)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953eb286",
   "metadata": {},
   "source": [
    "## 4. Tokenization and Model Training (Same as Approach 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b78a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n",
    "\n",
    "# Tokenization function (same as Approach 2)\n",
    "def tokenize_and_align_labels(examples, max_length=128):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        [ex['text'] for ex in examples],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True,\n",
    "        is_split_into_words=False\n",
    "    )\n",
    "    \n",
    "    aligned_labels = []\n",
    "    \n",
    "    for i, example in enumerate(examples):\n",
    "        word_labels = example['labels']\n",
    "        text = example['text']\n",
    "        offset_mapping = tokenized_inputs['offset_mapping'][i]\n",
    "        \n",
    "        char_labels = ['O'] * len(text)\n",
    "        char_pos = 0\n",
    "        \n",
    "        for word, label in zip(example['tokens'], word_labels):\n",
    "            word_start = text.find(word, char_pos)\n",
    "            if word_start != -1:\n",
    "                word_end = word_start + len(word)\n",
    "                for j in range(word_start, word_end):\n",
    "                    char_labels[j] = label\n",
    "                char_pos = word_end\n",
    "        \n",
    "        labels = []\n",
    "        for start, end in offset_mapping:\n",
    "            if start == 0 and end == 0:\n",
    "                labels.append(-100)\n",
    "            else:\n",
    "                if start < len(char_labels):\n",
    "                    labels.append(label2id.get(char_labels[start], 0))\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "        \n",
    "        aligned_labels.append(labels)\n",
    "    \n",
    "    tokenized_inputs.pop('offset_mapping')\n",
    "    tokenized_inputs['labels'] = aligned_labels\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "# Tokenize\n",
    "print(\"Tokenizing...\")\n",
    "train_tokenized = tokenize_and_align_labels(train_examples)\n",
    "val_tokenized = tokenize_and_align_labels(val_examples)\n",
    "test_tokenized = tokenize_and_align_labels(test_examples)\n",
    "print(\"‚úÖ Done\")\n",
    "\n",
    "# Create datasets\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "train_dataset = NERDataset(train_tokenized)\n",
    "val_dataset = NERDataset(val_tokenized)\n",
    "test_dataset = NERDataset(test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931cec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb530ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        true_label = []\n",
    "        pred_label = []\n",
    "        \n",
    "        for p, l in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                true_label.append(id2label[l])\n",
    "                pred_label.append(id2label[p])\n",
    "        \n",
    "        true_labels.append(true_label)\n",
    "        pred_labels.append(pred_label)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, pred_labels),\n",
    "        \"recall\": recall_score(true_labels, pred_labels),\n",
    "        \"f1\": f1_score(true_labels, pred_labels),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65789343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./entity-ner-model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bbcba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "print(\"üöÄ Training...\")\n",
    "trainer.train()\n",
    "print(\"‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f074f",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(\"üìä Evaluating...\")\n",
    "results = trainer.predict(test_dataset)\n",
    "predictions = np.argmax(results.predictions, axis=2)\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for prediction, label in zip(predictions, results.label_ids):\n",
    "    true_label = []\n",
    "    pred_label = []\n",
    "    \n",
    "    for p, l in zip(prediction, label):\n",
    "        if l != -100:\n",
    "            true_label.append(id2label[l])\n",
    "            pred_label.append(id2label[p])\n",
    "    \n",
    "    true_labels.append(true_label)\n",
    "    pred_labels.append(pred_label)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43df2ab",
   "metadata": {},
   "source": [
    "## 6. Entity Extraction + Claim Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text, model, tokenizer, id2label):\n",
    "    \"\"\"\n",
    "    Extract entities from text\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    \n",
    "    offset_mapping = inputs.pop('offset_mapping')[0]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    predictions = torch.argmax(outputs.logits, dim=2)[0]\n",
    "    probabilities = torch.softmax(outputs.logits, dim=2)[0]\n",
    "    \n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    \n",
    "    for idx, (pred, prob, (start, end)) in enumerate(zip(predictions, probabilities, offset_mapping)):\n",
    "        if start == 0 and end == 0:\n",
    "            continue\n",
    "        \n",
    "        label = id2label[pred.item()]\n",
    "        confidence = prob[pred].item()\n",
    "        \n",
    "        if label.startswith('B-'):\n",
    "            if current_entity:\n",
    "                entities.append(current_entity)\n",
    "            \n",
    "            current_entity = {\n",
    "                'type': label[2:],\n",
    "                'start': start.item(),\n",
    "                'end': end.item(),\n",
    "                'confidence': confidence\n",
    "            }\n",
    "        \n",
    "        elif label.startswith('I-') and current_entity:\n",
    "            if label[2:] == current_entity['type']:\n",
    "                current_entity['end'] = end.item()\n",
    "                current_entity['confidence'] = (current_entity['confidence'] + confidence) / 2\n",
    "        \n",
    "        elif label == 'O' and current_entity:\n",
    "            entities.append(current_entity)\n",
    "            current_entity = None\n",
    "    \n",
    "    if current_entity:\n",
    "        entities.append(current_entity)\n",
    "    \n",
    "    for entity in entities:\n",
    "        entity['text'] = text[entity['start']:entity['end']]\n",
    "    \n",
    "    return entities\n",
    "\n",
    "def parse_entities_to_claims(entities, text):\n",
    "    \"\"\"\n",
    "    Parse extracted entities into structured claims\n",
    "    This is a rule-based approach\n",
    "    \"\"\"\n",
    "    claims = []\n",
    "    \n",
    "    # IDENTITY_CLAIM: BRAND entities\n",
    "    for entity in entities:\n",
    "        if entity['type'] == 'BRAND':\n",
    "            claims.append({\n",
    "                'type': 'IDENTITY_CLAIM',\n",
    "                'text': entity['text'],\n",
    "                'evidence': f\"Claims to be from {entity['text']}\",\n",
    "                'confidence': entity['confidence']\n",
    "            })\n",
    "    \n",
    "    # ACTION_CLAIM: PHONE or URL entities\n",
    "    for entity in entities:\n",
    "        if entity['type'] in ['PHONE', 'URL']:\n",
    "            claims.append({\n",
    "                'type': 'ACTION_CLAIM',\n",
    "                'text': entity['text'],\n",
    "                'evidence': f\"Requests action via {entity['type'].lower()}\",\n",
    "                'confidence': entity['confidence']\n",
    "            })\n",
    "    \n",
    "    # FINANCIAL_CLAIM: AMOUNT entities\n",
    "    for entity in entities:\n",
    "        if entity['type'] == 'AMOUNT':\n",
    "            claims.append({\n",
    "                'type': 'FINANCIAL_CLAIM',\n",
    "                'text': entity['text'],\n",
    "                'evidence': f\"Mentions money: {entity['text']}\",\n",
    "                'confidence': entity['confidence']\n",
    "            })\n",
    "    \n",
    "    # ACCOUNT_CLAIM: ACCOUNT entities\n",
    "    for entity in entities:\n",
    "        if entity['type'] == 'ACCOUNT':\n",
    "            claims.append({\n",
    "                'type': 'ACCOUNT_CLAIM',\n",
    "                'text': entity['text'],\n",
    "                'evidence': f\"References account: {entity['text']}\",\n",
    "                'confidence': entity['confidence']\n",
    "            })\n",
    "    \n",
    "    # URGENCY_CLAIM: Check for urgency keywords\n",
    "    urgency_keywords = ['urgent', 'now', 'immediately', 'asap', 'today', 'expires', '24 hours']\n",
    "    text_lower = text.lower()\n",
    "    for keyword in urgency_keywords:\n",
    "        if keyword in text_lower:\n",
    "            claims.append({\n",
    "                'type': 'URGENCY_CLAIM',\n",
    "                'text': keyword,\n",
    "                'evidence': f\"Uses urgency language: '{keyword}'\",\n",
    "                'confidence': 0.8\n",
    "            })\n",
    "            break\n",
    "    \n",
    "    return claims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab4adc",
   "metadata": {},
   "source": [
    "## 7. Complete Pipeline Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec15b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test complete pipeline\n",
    "test_messages = [\n",
    "    \"Your Amazon package is delayed. Click here urgently to reschedule delivery.\",\n",
    "    \"URGENT: Your PayPal account suspended. Call 0800-123-456 now to verify.\",\n",
    "    \"You've won ¬£5000! Visit www.claim-prize.com immediately.\",\n",
    "]\n",
    "\n",
    "print(\"üîç TWO-STEP PIPELINE: Entity Extraction ‚Üí Claim Parsing\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, msg in enumerate(test_messages, 1):\n",
    "    print(f\"\\n{i}. Message: {msg}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Step 1: Extract entities\n",
    "    entities = extract_entities(msg, model, tokenizer, id2label)\n",
    "    print(f\"\\n   STEP 1 - Entities Extracted:\")\n",
    "    if entities:\n",
    "        for entity in entities:\n",
    "            print(f\"     - {entity['type']:10} : '{entity['text']}' (conf: {entity['confidence']:.2f})\")\n",
    "    else:\n",
    "        print(\"     (no entities found)\")\n",
    "    \n",
    "    # Step 2: Parse to claims\n",
    "    claims = parse_entities_to_claims(entities, msg)\n",
    "    print(f\"\\n   STEP 2 - Claims Parsed:\")\n",
    "    if claims:\n",
    "        for claim in claims:\n",
    "            print(f\"     - {claim['type']:20} : {claim['evidence']}\")\n",
    "    else:\n",
    "        print(\"     (no claims generated)\")\n",
    "    \n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138590d6",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_pretrained(\"./entity-ner-final\")\n",
    "tokenizer.save_pretrained(\"./entity-ner-final\")\n",
    "\n",
    "with open(\"./entity-ner-final/label_mappings.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        'label2id': label2id,\n",
    "        'id2label': {int(k): v for k, v in id2label.items()},\n",
    "        'entity_types': ENTITY_TYPES\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5893ea79",
   "metadata": {},
   "source": [
    "## 9. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f45200",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"APPROACH 1: ENTITY-FIRST NER\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Two-step pipeline:\")\n",
    "print(f\"  1. Extract entities (BRAND, PHONE, URL, etc.)\")\n",
    "print(f\"  2. Parse entities ‚Üí structured claims\")\n",
    "print(f\"\\nAdvantages:\")\n",
    "print(f\"  ‚úÖ Entities are concrete and well-defined\")\n",
    "print(f\"  ‚úÖ Clear intermediate representation\")\n",
    "print(f\"  ‚úÖ Reusable entity extraction\")\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"  Precision: {precision_score(true_labels, pred_labels):.3f}\")\n",
    "print(f\"  Recall:    {recall_score(true_labels, pred_labels):.3f}\")\n",
    "print(f\"  F1 Score:  {f1_score(true_labels, pred_labels):.3f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
