{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781132c0",
   "metadata": {},
   "source": [
    "# Approach 2: Claim-Phrase NER\n",
    "\n",
    "Train a RoBERTa-based NER model to directly extract claim phrases from SMS messages.\n",
    "\n",
    "## Overview\n",
    "- **Model**: RoBERTa-base for Token Classification\n",
    "- **Task**: Extract 12 types of claims using BIO tagging\n",
    "- **Labels**: IDENTITY_CLAIM, DELIVERY_CLAIM, FINANCIAL_CLAIM, ACCOUNT_CLAIM, URGENCY_CLAIM, ACTION_CLAIM, VERIFICATION_CLAIM, SECURITY_CLAIM, REWARD_CLAIM, LEGAL_CLAIM, SOCIAL_CLAIM, CREDENTIALS_CLAIM\n",
    "- **Advantages**: Direct semantic capture, robust to variations, handles implicit claims\n",
    "\n",
    "## Setup Instructions\n",
    "1. Upload `claim_annotations_2000.json` to Colab\n",
    "2. Run all cells in order\n",
    "3. Model will be saved to Google Drive (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f0e96",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ffc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets accelerate seqeval scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a51884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ae885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional - for saving models)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data file\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üìÅ Please upload 'claim_annotations_2000.json'\")\n",
    "uploaded = files.upload()\n",
    "data_file = list(uploaded.keys())[0]\n",
    "print(f\"‚úÖ Uploaded: {data_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79343b5",
   "metadata": {},
   "source": [
    "## 2. Define Claim Types and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe1b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 12 claim types\n",
    "CLAIM_TYPES = [\n",
    "    'IDENTITY_CLAIM',      # \"We are Amazon/PayPal/IRS\"\n",
    "    'DELIVERY_CLAIM',      # \"Your package is delayed/stuck\"\n",
    "    'FINANCIAL_CLAIM',     # \"You won $5000 / Prize available\"\n",
    "    'ACCOUNT_CLAIM',       # \"Your account is suspended/locked\"\n",
    "    'URGENCY_CLAIM',       # \"Act now / Expires tonight\"\n",
    "    'ACTION_CLAIM',        # \"Click here / Call immediately\"\n",
    "    'VERIFICATION_CLAIM',  # \"Verify your identity / Confirm details\"\n",
    "    'SECURITY_CLAIM',      # \"Suspicious activity / Unauthorized access\"\n",
    "    'REWARD_CLAIM',        # \"Loyalty bonus / Cashback available\"\n",
    "    'LEGAL_CLAIM',         # \"Legal action / Tax penalty / Court summons\"\n",
    "    'SOCIAL_CLAIM',        # \"Friend/family needs help\"\n",
    "    'CREDENTIALS_CLAIM'    # \"Update password / Reset PIN\"\n",
    "]\n",
    "\n",
    "# Create BIO labels\n",
    "labels = ['O']  # Outside any claim\n",
    "for claim_type in CLAIM_TYPES:\n",
    "    labels.append(f'B-{claim_type}')  # Beginning\n",
    "    labels.append(f'I-{claim_type}')  # Inside\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(f\"Total labels: {len(labels)}\")\n",
    "print(f\"\\nLabel structure:\")\n",
    "print(f\"  - O (outside): 1 label\")\n",
    "print(f\"  - B-/I- tags: {len(CLAIM_TYPES)} √ó 2 = {len(CLAIM_TYPES)*2} labels\")\n",
    "print(f\"\\nFirst 10 labels: {labels[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df4c72",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea907f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bio_format(text, claim_spans):\n",
    "    \"\"\"\n",
    "    Convert text and claim spans to BIO format at word level\n",
    "    \n",
    "    Args:\n",
    "        text: The SMS message text\n",
    "        claim_spans: List of {'text', 'start', 'end', 'label'} dicts\n",
    "    \n",
    "    Returns:\n",
    "        tokens, labels: Lists of words and their BIO labels\n",
    "    \"\"\"\n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "    bio_labels = ['O'] * len(words)\n",
    "    \n",
    "    # Track character position\n",
    "    char_pos = 0\n",
    "    \n",
    "    for word_idx, word in enumerate(words):\n",
    "        # Find word position in text\n",
    "        word_start = text.find(word, char_pos)\n",
    "        if word_start == -1:\n",
    "            continue\n",
    "            \n",
    "        word_end = word_start + len(word)\n",
    "        char_pos = word_end\n",
    "        \n",
    "        # Check if word overlaps with any claim span\n",
    "        for span in claim_spans:\n",
    "            span_start = span['start']\n",
    "            span_end = span['end']\n",
    "            claim_label = span['label']\n",
    "            \n",
    "            # Check overlap\n",
    "            if not (word_end <= span_start or word_start >= span_end):\n",
    "                # Word overlaps with claim\n",
    "                # Use B- if word starts the claim, otherwise I-\n",
    "                if word_start <= span_start < word_end:\n",
    "                    bio_labels[word_idx] = f'B-{claim_label}'\n",
    "                else:\n",
    "                    # Check if previous word was also in this claim\n",
    "                    if word_idx > 0 and bio_labels[word_idx-1] in [f'B-{claim_label}', f'I-{claim_label}']:\n",
    "                        bio_labels[word_idx] = f'I-{claim_label}'\n",
    "                    else:\n",
    "                        bio_labels[word_idx] = f'B-{claim_label}'\n",
    "                break\n",
    "    \n",
    "    return words, bio_labels\n",
    "\n",
    "# Test the BIO conversion\n",
    "test_text = \"Your Amazon package is delayed. Click here urgently.\"\n",
    "test_spans = [\n",
    "    {'text': 'Amazon', 'start': 5, 'end': 11, 'label': 'IDENTITY_CLAIM'},\n",
    "    {'text': 'package is delayed', 'start': 12, 'end': 30, 'label': 'DELIVERY_CLAIM'},\n",
    "    {'text': 'Click here', 'start': 32, 'end': 42, 'label': 'ACTION_CLAIM'},\n",
    "    {'text': 'urgently', 'start': 43, 'end': 51, 'label': 'URGENCY_CLAIM'}\n",
    "]\n",
    "\n",
    "test_words, test_labels = convert_to_bio_format(test_text, test_spans)\n",
    "print(\"Test BIO conversion:\")\n",
    "for word, label in zip(test_words, test_labels):\n",
    "    print(f\"  {word:15} -> {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3656a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and convert annotations\n",
    "def load_claim_data(json_file):\n",
    "    \"\"\"Load claim annotations and convert to NER format\"\"\"\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    examples = []\n",
    "    \n",
    "    for entry in data:\n",
    "        text = entry['data']['text']\n",
    "        \n",
    "        # Check if has annotations\n",
    "        if not entry.get('annotations') or len(entry['annotations']) == 0:\n",
    "            continue\n",
    "        \n",
    "        annotations = entry['annotations'][0]\n",
    "        \n",
    "        # Extract claim spans\n",
    "        claim_spans = []\n",
    "        if 'result' in annotations and annotations['result']:\n",
    "            for result in annotations['result']:\n",
    "                value = result.get('value', {})\n",
    "                labels_list = value.get('labels', [])\n",
    "                \n",
    "                if labels_list:\n",
    "                    claim_spans.append({\n",
    "                        'text': value.get('text', ''),\n",
    "                        'start': value.get('start', 0),\n",
    "                        'end': value.get('end', 0),\n",
    "                        'label': labels_list[0]\n",
    "                    })\n",
    "        \n",
    "        # Convert to BIO format\n",
    "        tokens, bio_labels = convert_to_bio_format(text, claim_spans)\n",
    "        \n",
    "        examples.append({\n",
    "            'id': entry.get('id'),\n",
    "            'text': text,\n",
    "            'tokens': tokens,\n",
    "            'labels': bio_labels,\n",
    "            'claim_spans': claim_spans\n",
    "        })\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "examples = load_claim_data(data_file)\n",
    "print(f\"‚úÖ Loaded {len(examples)} examples\")\n",
    "\n",
    "# Show first example\n",
    "print(\"\\nüìù First example:\")\n",
    "ex = examples[0]\n",
    "print(f\"  Text: {ex['text'][:80]}...\")\n",
    "print(f\"  Tokens: {ex['tokens'][:5]}...\")\n",
    "print(f\"  Labels: {ex['labels'][:5]}...\")\n",
    "print(f\"  Claims: {len(ex['claim_spans'])} spans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac68a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_examples, test_examples = train_test_split(examples, test_size=0.15, random_state=42)\n",
    "train_examples, val_examples = train_test_split(train_examples, test_size=0.176, random_state=42)  # 0.15/0.85\n",
    "\n",
    "print(f\"Dataset split:\")\n",
    "print(f\"  Train: {len(train_examples)} examples\")\n",
    "print(f\"  Val:   {len(val_examples)} examples\")\n",
    "print(f\"  Test:  {len(test_examples)} examples\")\n",
    "\n",
    "# Count labels\n",
    "from collections import Counter\n",
    "all_labels = []\n",
    "for ex in train_examples:\n",
    "    all_labels.extend(ex['labels'])\n",
    "\n",
    "label_counts = Counter(all_labels)\n",
    "print(f\"\\nüìä Label distribution in training set:\")\n",
    "for label, count in sorted(label_counts.items(), key=lambda x: -x[1])[:15]:\n",
    "    print(f\"  {label:25} : {count:5} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ab122",
   "metadata": {},
   "source": [
    "## 4. Tokenization and Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71570c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "MODEL_NAME = \"roberta-base\"  # or \"distilroberta-base\" for faster training\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n",
    "\n",
    "print(f\"‚úÖ Loaded tokenizer: {MODEL_NAME}\")\n",
    "print(f\"   Vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275dc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, max_length=128):\n",
    "    \"\"\"\n",
    "    Tokenize text and align labels with subword tokens\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        [ex['text'] for ex in examples],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True,\n",
    "        is_split_into_words=False\n",
    "    )\n",
    "    \n",
    "    aligned_labels = []\n",
    "    \n",
    "    for i, example in enumerate(examples):\n",
    "        word_labels = example['labels']\n",
    "        text = example['text']\n",
    "        offset_mapping = tokenized_inputs['offset_mapping'][i]\n",
    "        \n",
    "        # Create character-level label map\n",
    "        char_labels = ['O'] * len(text)\n",
    "        char_pos = 0\n",
    "        \n",
    "        for word, label in zip(example['tokens'], word_labels):\n",
    "            word_start = text.find(word, char_pos)\n",
    "            if word_start != -1:\n",
    "                word_end = word_start + len(word)\n",
    "                for j in range(word_start, word_end):\n",
    "                    char_labels[j] = label\n",
    "                char_pos = word_end\n",
    "        \n",
    "        # Align with subword tokens\n",
    "        labels = []\n",
    "        for start, end in offset_mapping:\n",
    "            if start == 0 and end == 0:\n",
    "                # Special token\n",
    "                labels.append(-100)\n",
    "            else:\n",
    "                # Use label of first character\n",
    "                if start < len(char_labels):\n",
    "                    labels.append(label2id.get(char_labels[start], 0))\n",
    "                else:\n",
    "                    labels.append(0)  # O label\n",
    "        \n",
    "        aligned_labels.append(labels)\n",
    "    \n",
    "    # Remove offset_mapping (not needed for training)\n",
    "    tokenized_inputs.pop('offset_mapping')\n",
    "    tokenized_inputs['labels'] = aligned_labels\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "print(\"Tokenizing datasets...\")\n",
    "train_tokenized = tokenize_and_align_labels(train_examples)\n",
    "val_tokenized = tokenize_and_align_labels(val_examples)\n",
    "test_tokenized = tokenize_and_align_labels(test_examples)\n",
    "print(\"‚úÖ Tokenization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: torch.tensor(val[idx]) \n",
    "            for key, val in self.encodings.items()\n",
    "        }\n",
    "\n",
    "train_dataset = NERDataset(train_tokenized)\n",
    "val_dataset = NERDataset(val_tokenized)\n",
    "test_dataset = NERDataset(test_tokenized)\n",
    "\n",
    "print(f\"‚úÖ Created PyTorch datasets\")\n",
    "print(f\"   Train: {len(train_dataset)}\")\n",
    "print(f\"   Val: {len(val_dataset)}\")\n",
    "print(f\"   Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf517a1",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Loaded model: {MODEL_NAME}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    # Convert to label strings (ignore -100)\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        true_label = []\n",
    "        pred_label = []\n",
    "        \n",
    "        for p, l in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                true_label.append(id2label[l])\n",
    "                pred_label.append(id2label[p])\n",
    "        \n",
    "        true_labels.append(true_label)\n",
    "        pred_labels.append(pred_label)\n",
    "    \n",
    "    # Compute metrics\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, pred_labels),\n",
    "        \"recall\": recall_score(true_labels, pred_labels),\n",
    "        \"f1\": f1_score(true_labels, pred_labels),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12e32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./claim-ner-model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üöÄ Starting training...\")\n",
    "trainer.train()\n",
    "print(\"‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a476a0",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d1ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"üìä Evaluating on test set...\")\n",
    "results = trainer.predict(test_dataset)\n",
    "predictions = np.argmax(results.predictions, axis=2)\n",
    "\n",
    "# Convert to label strings\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for prediction, label in zip(predictions, results.label_ids):\n",
    "    true_label = []\n",
    "    pred_label = []\n",
    "    \n",
    "    for p, l in zip(prediction, label):\n",
    "        if l != -100:\n",
    "            true_label.append(id2label[l])\n",
    "            pred_label.append(id2label[p])\n",
    "    \n",
    "    true_labels.append(true_label)\n",
    "    pred_labels.append(pred_label)\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59efd203",
   "metadata": {},
   "source": [
    "## 7. Inference Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f55718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_claims(text, model, tokenizer, id2label):\n",
    "    \"\"\"\n",
    "    Extract claims from a text message\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    \n",
    "    offset_mapping = inputs.pop('offset_mapping')[0]\n",
    "    \n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    predictions = torch.argmax(outputs.logits, dim=2)[0]\n",
    "    probabilities = torch.softmax(outputs.logits, dim=2)[0]\n",
    "    \n",
    "    # Extract claims\n",
    "    claims = []\n",
    "    current_claim = None\n",
    "    \n",
    "    for idx, (pred, prob, (start, end)) in enumerate(zip(predictions, probabilities, offset_mapping)):\n",
    "        if start == 0 and end == 0:\n",
    "            continue\n",
    "        \n",
    "        label = id2label[pred.item()]\n",
    "        confidence = prob[pred].item()\n",
    "        \n",
    "        if label.startswith('B-'):\n",
    "            # Start new claim\n",
    "            if current_claim:\n",
    "                claims.append(current_claim)\n",
    "            \n",
    "            current_claim = {\n",
    "                'type': label[2:],\n",
    "                'start': start.item(),\n",
    "                'end': end.item(),\n",
    "                'confidence': confidence\n",
    "            }\n",
    "        \n",
    "        elif label.startswith('I-') and current_claim:\n",
    "            # Continue current claim\n",
    "            if label[2:] == current_claim['type']:\n",
    "                current_claim['end'] = end.item()\n",
    "                current_claim['confidence'] = (current_claim['confidence'] + confidence) / 2\n",
    "        \n",
    "        elif label == 'O' and current_claim:\n",
    "            # End current claim\n",
    "            claims.append(current_claim)\n",
    "            current_claim = None\n",
    "    \n",
    "    if current_claim:\n",
    "        claims.append(current_claim)\n",
    "    \n",
    "    # Add text to claims\n",
    "    for claim in claims:\n",
    "        claim['text'] = text[claim['start']:claim['end']]\n",
    "    \n",
    "    return claims\n",
    "\n",
    "# Test with examples\n",
    "test_messages = [\n",
    "    \"Your Amazon package is delayed. Click here urgently to reschedule delivery.\",\n",
    "    \"URGENT: Your PayPal account has been suspended. Verify your identity now to avoid legal action.\",\n",
    "    \"Congratulations! You've won ¬£5000. Call 0800-123-456 to claim your prize today.\",\n",
    "    \"Hi, are we still meeting for lunch?\"\n",
    "]\n",
    "\n",
    "print(\"üîç Testing claim extraction:\\n\")\n",
    "for i, msg in enumerate(test_messages, 1):\n",
    "    print(f\"\\n{i}. Message: {msg}\")\n",
    "    claims = extract_claims(msg, model, tokenizer, id2label)\n",
    "    \n",
    "    if claims:\n",
    "        print(f\"   Found {len(claims)} claims:\")\n",
    "        for claim in claims:\n",
    "            print(f\"     - {claim['type']:20} : '{claim['text']}' (conf: {claim['confidence']:.2f})\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ No claims detected (likely HAM)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fe257",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model locally\n",
    "model.save_pretrained(\"./claim-ner-final\")\n",
    "tokenizer.save_pretrained(\"./claim-ner-final\")\n",
    "\n",
    "# Save label mappings\n",
    "import json\n",
    "with open(\"./claim-ner-final/label_mappings.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        'label2id': label2id,\n",
    "        'id2label': {int(k): v for k, v in id2label.items()},\n",
    "        'claim_types': CLAIM_TYPES\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Model saved to ./claim-ner-final/\")\n",
    "\n",
    "# Download model (optional)\n",
    "# !zip -r claim-ner-final.zip ./claim-ner-final\n",
    "# from google.colab import files\n",
    "# files.download('claim-ner-final.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c90cb5",
   "metadata": {},
   "source": [
    "## 9. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6406698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SUMMARY - APPROACH 2: CLAIM-PHRASE NER\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Training examples: {len(train_dataset)}\")\n",
    "print(f\"Validation examples: {len(val_dataset)}\")\n",
    "print(f\"Test examples: {len(test_dataset)}\")\n",
    "print(f\"\\nNumber of claim types: {len(CLAIM_TYPES)}\")\n",
    "print(f\"Total labels (BIO): {len(labels)}\")\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"  Precision: {precision_score(true_labels, pred_labels):.3f}\")\n",
    "print(f\"  Recall:    {recall_score(true_labels, pred_labels):.3f}\")\n",
    "print(f\"  F1 Score:  {f1_score(true_labels, pred_labels):.3f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
