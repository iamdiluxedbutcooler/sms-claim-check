{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af22a242",
   "metadata": {},
   "source": [
    "# SMS Claim Extraction - Training on Colab\n",
    "\n",
    "This notebook trains all 4 approaches for claim extraction research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed20678",
   "metadata": {},
   "source": [
    "## ðŸš€ Setup Instructions\n",
    "\n",
    "**Before running:**\n",
    "1. Replace `YOUR_PROJECT_ID` with your GCP project ID\n",
    "2. Replace `your-bucket-name` with your GCS bucket name\n",
    "3. Make sure your GCS bucket exists and you have write permissions\n",
    "\n",
    "**What this notebook does:**\n",
    "- Uses K-Fold Cross-Validation (5 folds) for robust training\n",
    "- Keeps test set BLIND until final evaluation\n",
    "- Saves all checkpoints to Google Cloud Storage\n",
    "- No more Drive storage issues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/iamdiluxedbutcooler/sms-claim-check.git\n",
    "%cd sms-claim-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (including GCS support)\n",
    "!pip install -q transformers datasets torch scikit-learn pandas numpy seaborn matplotlib openai python-dotenv evaluate accelerate sentencepiece seqeval google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017201aa",
   "metadata": {},
   "source": [
    "## Setup Google Cloud Storage\n",
    "\n",
    "Authenticate and configure GCS bucket for saving checkpoints and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1bcdd",
   "metadata": {},
   "source": [
    "## Update Code (if needed)\n",
    "\n",
    "Run this cell ONLY if you need to pull latest code updates. It will backup experiments first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup experiments before updating code\n",
    "!cp -r experiments /content/drive/MyDrive/sms-claim-check/backup_experiments_$(date +%Y%m%d_%H%M%S) 2>/dev/null || echo \"No experiments to backup yet\"\n",
    "\n",
    "# Pull latest code\n",
    "!git pull origin main\n",
    "\n",
    "# IMPORTANT: Restart runtime after pulling to reload modules\n",
    "print(\"\\n[WARNING] After pulling, go to Runtime > Restart runtime to reload updated code!\")\n",
    "print(\"Then continue from where you left off.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUICK FIX: Reload modules without restarting runtime\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Remove cached modules\n",
    "modules_to_reload = [m for m in sys.modules.keys() if m.startswith('src.')]\n",
    "for module in modules_to_reload:\n",
    "    del sys.modules[module]\n",
    "\n",
    "# Reload\n",
    "import src.models\n",
    "import src.data\n",
    "\n",
    "print(\"[OK] Modules reloaded! Continue training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153377aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Google Cloud\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Configure GCS\n",
    "import os\n",
    "os.environ['GCLOUD_PROJECT'] = 'YOUR_PROJECT_ID'  # Replace with your GCP project ID\n",
    "\n",
    "# Test GCS connection\n",
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "\n",
    "# Set your bucket name\n",
    "GCS_BUCKET_NAME = 'your-bucket-name'  # Replace with your bucket name\n",
    "bucket = client.bucket(GCS_BUCKET_NAME)\n",
    "\n",
    "print(f\"âœ“ Authenticated and connected to GCS bucket: {GCS_BUCKET_NAME}\")\n",
    "print(f\"âœ“ Project: {os.environ['GCLOUD_PROJECT']}\")\n",
    "\n",
    "# Create folder structure in bucket\n",
    "print(\"\\nBucket ready for checkpoints and results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832986bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724d6ad",
   "metadata": {},
   "source": [
    "## Optional: Download Checkpoint from GCS\n",
    "\n",
    "If you need to resume training or load a previous checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_gcs(gcs_folder_path, local_folder):\n",
    "    \"\"\"Download folder from GCS to local\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(GCS_BUCKET_NAME)\n",
    "    \n",
    "    # List all blobs with prefix\n",
    "    blobs = bucket.list_blobs(prefix=gcs_folder_path)\n",
    "    \n",
    "    file_count = 0\n",
    "    for blob in blobs:\n",
    "        # Create local path\n",
    "        relative_path = blob.name[len(gcs_folder_path):].lstrip('/')\n",
    "        local_path = Path(local_folder) / relative_path\n",
    "        \n",
    "        # Create parent directories\n",
    "        local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Download file\n",
    "        blob.download_to_filename(str(local_path))\n",
    "        file_count += 1\n",
    "    \n",
    "    print(f'[DOWNLOADED] {file_count} files from gs://{GCS_BUCKET_NAME}/{gcs_folder_path} -> {local_folder}')\n",
    "\n",
    "# Example: Download latest checkpoint for approach 1\n",
    "# download_from_gcs('checkpoints/approach1_entity_ner_latest', 'experiments/approach1_entity_ner')\n",
    "\n",
    "print(\"âœ“ Download function ready. Uncomment example above to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cea5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GCS auto-save function\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from google.cloud import storage\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def upload_folder_to_gcs(local_folder, gcs_folder_path):\n",
    "    \"\"\"Upload entire folder to GCS\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(GCS_BUCKET_NAME)\n",
    "    \n",
    "    local_path = Path(local_folder)\n",
    "    if not local_path.exists():\n",
    "        print(f\"[SKIP] Folder not found: {local_folder}\")\n",
    "        return\n",
    "    \n",
    "    file_count = 0\n",
    "    for file_path in local_path.rglob('*'):\n",
    "        if file_path.is_file():\n",
    "            # Create blob path relative to local folder\n",
    "            relative_path = file_path.relative_to(local_path.parent)\n",
    "            blob_path = f\"{gcs_folder_path}/{relative_path}\"\n",
    "            \n",
    "            # Upload file\n",
    "            blob = bucket.blob(blob_path)\n",
    "            blob.upload_from_filename(str(file_path))\n",
    "            file_count += 1\n",
    "    \n",
    "    print(f'[SAVED] {file_count} files from {local_folder} -> gs://{GCS_BUCKET_NAME}/{gcs_folder_path}')\n",
    "\n",
    "def save_checkpoint(approach_name):\n",
    "    \"\"\"Save checkpoint to GCS\"\"\"\n",
    "    source = f'experiments/{approach_name}'\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    gcs_path = f'checkpoints/{approach_name}_{timestamp}'\n",
    "    \n",
    "    upload_folder_to_gcs(source, gcs_path)\n",
    "    \n",
    "    # Also save as \"latest\"\n",
    "    latest_path = f'checkpoints/{approach_name}_latest'\n",
    "    upload_folder_to_gcs(source, latest_path)\n",
    "    \n",
    "    print(f'âœ“ Checkpoint saved to GCS')\n",
    "\n",
    "def save_all_results():\n",
    "    \"\"\"Save all results to GCS\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    upload_folder_to_gcs('experiments', f'results/experiments_{timestamp}')\n",
    "    upload_folder_to_gcs('experiments', 'results/experiments_latest')\n",
    "    print('[SAVED] All results -> GCS')\n",
    "\n",
    "print('âœ“ GCS auto-save setup complete!')\n",
    "print(f'âœ“ Bucket: gs://{GCS_BUCKET_NAME}')\n",
    "print(f'âœ“ Checkpoints will be saved to: checkpoints/<approach>_<timestamp>/')\n",
    "print(f'âœ“ Results will be saved to: results/experiments_<timestamp>/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d6f88b",
   "metadata": {},
   "source": [
    "## Approach 1: Entity-based NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_kfold.py --config configs/entity_ner.yaml --n_folds 5\n",
    "\n",
    "# Save checkpoint to GCS\n",
    "save_checkpoint('approach1_entity_ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2d227",
   "metadata": {},
   "source": [
    "## Approach 2: Claim-based NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615312e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_kfold.py --config configs/claim_ner.yaml --n_folds 5\n",
    "\n",
    "# Save checkpoint to GCS\n",
    "save_checkpoint('approach2_claim_ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aa0b2a",
   "metadata": {},
   "source": [
    "## Approach 4: Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_kfold.py --config configs/contrastive.yaml --n_folds 5\n",
    "\n",
    "# Save checkpoint to GCS\n",
    "save_checkpoint('approach4_contrastive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054255e5",
   "metadata": {},
   "source": [
    "## Approach 3a: Hybrid Entity + LLM (Inference Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6291e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'YOUR_API_KEY_HERE'  # Replace with your key\n",
    "\n",
    "!python inference.py --config configs/hybrid_llm.yaml --model experiments/approach1_entity_ner/best_model\n",
    "\n",
    "# Save results to Drive\n",
    "save_checkpoint('approach3_hybrid_llm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c50ab90",
   "metadata": {},
   "source": [
    "## Approach 3b: Hybrid Claim + LLM (Inference Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference.py --config configs/hybrid_claim_llm.yaml --model experiments/approach2_claim_ner/best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2b2b3",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/compare_models.py\n",
    "\n",
    "# Save final comparison to Drive\n",
    "save_all_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf115d3",
   "metadata": {},
   "source": [
    "## Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f57939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final save to GCS\n",
    "save_all_results()\n",
    "\n",
    "# Optional: Also zip and download locally\n",
    "!zip -r results.zip experiments/\n",
    "from google.colab import files\n",
    "files.download('results.zip')\n",
    "\n",
    "print('[COMPLETE] All results saved to GCS!')\n",
    "print(f'View in console: https://console.cloud.google.com/storage/browser/{GCS_BUCKET_NAME}/results/')\n",
    "print(f'Checkpoints: https://console.cloud.google.com/storage/browser/{GCS_BUCKET_NAME}/checkpoints/')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
